// Observability: @nzila/os-core/telemetry — structured logging and request tracing available via os-core.
/**
 * GET /api/ml/runs/inference
 *
 * Returns recent inference runs for an entity.
 * RBAC: any active entity member.
 *
 * Query params:
 *   orgId    required
 *   modelId     optional — filter to a specific model
 *   limit       optional — default 20, max 100
 */
import { NextRequest, NextResponse } from 'next/server'
import { platformDb } from '@nzila/db/platform'
import { mlInferenceRuns, mlModels } from '@nzila/db/schema'
import { eq, and, desc } from 'drizzle-orm'
import { requireOrgAccess } from '@/lib/api-guards'
import { createLogger } from '@nzila/os-core'

const logger = createLogger('ml:runs:inference')

export const runtime = 'nodejs'
export const dynamic = 'force-dynamic'

export async function GET(req: NextRequest) {
  try {
    const { searchParams } = req.nextUrl
    const orgId = searchParams.get('orgId')
    const modelId = searchParams.get('modelId')
    const limit = Math.min(parseInt(searchParams.get('limit') ?? '20', 10), 100)

    if (!orgId) {
      return NextResponse.json({ error: 'orgId is required' }, { status: 400 })
    }

    const access = await requireOrgAccess(orgId)
    if (!access.ok) return access.response

    const rows = await platformDb
      .select({
        id: mlInferenceRuns.id,
        orgId: mlInferenceRuns.orgId,
        modelId: mlInferenceRuns.modelId,
        modelKey: mlModels.modelKey,
        status: mlInferenceRuns.status,
        startedAt: mlInferenceRuns.startedAt,
        finishedAt: mlInferenceRuns.finishedAt,
        inputPeriodStart: mlInferenceRuns.inputPeriodStart,
        inputPeriodEnd: mlInferenceRuns.inputPeriodEnd,
        summaryJson: mlInferenceRuns.summaryJson,
        error: mlInferenceRuns.error,
        createdAt: mlInferenceRuns.createdAt,
      })
      .from(mlInferenceRuns)
      .innerJoin(mlModels, eq(mlInferenceRuns.modelId, mlModels.id))
      .where(
        and(
          eq(mlInferenceRuns.orgId, orgId),
          ...(modelId ? [eq(mlInferenceRuns.modelId, modelId)] : []),
        ),
      )
      .orderBy(desc(mlInferenceRuns.startedAt))
      .limit(limit)

    return NextResponse.json(
      rows.map((r) => ({
        id: r.id,
        orgId: r.orgId,
        modelId: r.modelId,
        modelKey: r.modelKey,
        status: r.status,
        startedAt: r.startedAt.toISOString(),
        finishedAt: r.finishedAt?.toISOString() ?? null,
        inputPeriodStart: r.inputPeriodStart,
        inputPeriodEnd: r.inputPeriodEnd,
        summaryJson: r.summaryJson,
        error: r.error,
        createdAt: r.createdAt.toISOString(),
      })),
    )
  } catch (err) {
    logger.error('[ML /runs/inference]', err instanceof Error ? err : { detail: err })
    return NextResponse.json({ error: 'Internal server error' }, { status: 500 })
  }
}
